<!DOCTYPE html>
<!-- saved from url=(0055)https://google.github.io/mediapipe/solutions/hands.html -->
<html lang="en-US"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">  <meta http-equiv="X-UA-Compatible" content="IE=Edge"> <title>Hands - mediapipe</title> <link rel="shortcut icon" href="https://google.github.io/mediapipe/favicon.ico" type="image/x-icon"> <link rel="stylesheet" href="./Hands_files/just-the-docs-default.css"> <script type="text/javascript" async="" src="./Hands_files/analytics.js.download"></script><script async="" src="./Hands_files/js"></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-140696581-2'); </script> <script type="text/javascript" src="./Hands_files/lunr.min.js.download"></script> <script type="text/javascript" src="./Hands_files/just-the-docs.js.download"></script> <meta name="viewport" content="width=device-width, initial-scale=1"> <!-- Begin Jekyll SEO tag v2.8.0 --> <title>Hands | mediapipe</title> <meta name="generator" content="Jekyll v3.9.2"> <meta property="og:title" content="Hands"> <meta property="og:locale" content="en_US"> <meta name="description" content="Cross-platform, customizable ML solutions for live and streaming media."> <meta property="og:description" content="Cross-platform, customizable ML solutions for live and streaming media."> <link rel="canonical" href="https://google.github.io/mediapipe/solutions/hands.html"> <meta property="og:url" content="https://google.github.io/mediapipe/solutions/hands.html"> <meta property="og:site_name" content="mediapipe"> <meta property="og:type" content="website"> <meta name="twitter:card" content="summary"> <meta property="twitter:title" content="Hands"> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"WebPage","description":"Cross-platform, customizable ML solutions for live and streaming media.","headline":"Hands","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"https://google.github.io/mediapipe/images/logo_horizontal_color.png"}},"url":"https://google.github.io/mediapipe/solutions/hands.html"}</script> <!-- End Jekyll SEO tag --> </head> <body> <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"> <symbol id="svg-link" viewBox="0 0 24 24"> <title>Link</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"> <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"> <title>Search</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"> <title>Menu</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"> <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"> <title>Expand</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"> <polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"> <title>Document</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"> <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> </svg> <div class="side-bar"> <div class="site-header"> <a href="https://google.github.io/mediapipe/" class="site-title lh-tight"> <div class="site-logo"></div> </a> <a href="https://google.github.io/mediapipe/solutions/hands.html#" id="menu-button" class="site-button"> <svg viewBox="0 0 24 24" class="icon"><use xlink:href="#svg-menu"></use></svg> </a> </div> <nav role="navigation" aria-label="Main" id="site-nav" class="site-nav"> <ul class="nav-list"><li class="nav-list-item"><a href="https://google.github.io/mediapipe/" class="nav-list-link">Home</a></li><li class="nav-list-item"><a href="https://google.github.io/mediapipe/solutions/hands.html#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="https://google.github.io/mediapipe/getting_started/getting_started.html" class="nav-list-link">Getting Started</a><ul class="nav-list "><li class="nav-list-item "><a href="https://google.github.io/mediapipe/solutions/hands.html#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="https://google.github.io/mediapipe/getting_started/android.html" class="nav-list-link">MediaPipe on Android</a><ul class="nav-list"><li class="nav-list-item "> <a href="https://google.github.io/mediapipe/getting_started/hello_world_android.html" class="nav-list-link">Hello World! on Android</a> </li><li class="nav-list-item "> <a href="https://google.github.io/mediapipe/getting_started/android_solutions.html" class="nav-list-link">MediaPipe Android Solutions</a> </li><li class="nav-list-item "> <a href="https://google.github.io/mediapipe/getting_started/android_archive_library.html" class="nav-list-link">MediaPipe Android Archive</a> </li></ul></li><li class="nav-list-item "><a href="https://google.github.io/mediapipe/solutions/hands.html#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="https://google.github.io/mediapipe/getting_started/ios.html" class="nav-list-link">MediaPipe on iOS</a><ul class="nav-list"><li class="nav-list-item "> <a href="https://google.github.io/mediapipe/getting_started/hello_world_ios.html" class="nav-list-link">Hello World! on iOS</a> </li></ul></li><li class="nav-list-item "><a href="https://google.github.io/mediapipe/solutions/hands.html#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="https://google.github.io/mediapipe/getting_started/python.html" class="nav-list-link">MediaPipe in Python</a><ul class="nav-list"><li class="nav-list-item "> <a href="https://google.github.io/mediapipe/getting_started/python_framework.html" class="nav-list-link">MediaPipe Python Framework</a> </li></ul></li><li class="nav-list-item "><a href="https://google.github.io/mediapipe/getting_started/javascript.html" class="nav-list-link">MediaPipe in JavaScript</a></li><li class="nav-list-item "><a href="https://google.github.io/mediapipe/solutions/hands.html#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="https://google.github.io/mediapipe/getting_started/cpp.html" class="nav-list-link">MediaPipe in C++</a><ul class="nav-list"><li class="nav-list-item "> <a href="https://google.github.io/mediapipe/getting_started/hello_world_cpp.html" class="nav-list-link">Hello World! in C++</a> </li></ul></li><li class="nav-list-item "><a href="https://google.github.io/mediapipe/getting_started/install.html" class="nav-list-link">Installation</a></li><li class="nav-list-item "><a href="https://google.github.io/mediapipe/getting_started/gpu_support.html" class="nav-list-link">GPU Support</a></li><li class="nav-list-item "><a href="https://google.github.io/mediapipe/getting_started/help.html" class="nav-list-link">Getting Help</a></li><li class="nav-list-item "><a href="https://google.github.io/mediapipe/getting_started/faq.html" class="nav-list-link">FAQ</a></li><li class="nav-list-item "><a href="https://google.github.io/mediapipe/getting_started/troubleshooting.html" class="nav-list-link">Troubleshooting</a></li></ul></li><li class="nav-list-item active"><a href="https://google.github.io/mediapipe/solutions/hands.html#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="https://google.github.io/mediapipe/solutions/solutions.html" class="nav-list-link">Solutions</a><ul class="nav-list "><li class="nav-list-item "><a href="https://google.github.io/mediapipe/solutions/face_detection.html" class="nav-list-link">Face Detection</a></li><li class="nav-list-item "><a href="https://google.github.io/mediapipe/solutions/face_mesh.html" class="nav-list-link">Face Mesh</a></li><li class="nav-list-item "><a href="https://google.github.io/mediapipe/solutions/iris.html" class="nav-list-link">Iris</a></li><li class="nav-list-item active"><a href="https://google.github.io/mediapipe/solutions/hands.html" class="nav-list-link active">Hands</a></li><li class="nav-list-item "><a href="https://google.github.io/mediapipe/solutions/hands.html#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="https://google.github.io/mediapipe/solutions/pose.html" class="nav-list-link">Pose</a><ul class="nav-list"><li class="nav-list-item "> <a href="https://google.github.io/mediapipe/solutions/pose_classification.html" class="nav-list-link">Pose Classification</a> </li></ul></li><li class="nav-list-item "><a href="https://google.github.io/mediapipe/solutions/holistic.html" class="nav-list-link">Holistic</a></li><li class="nav-list-item "><a href="https://google.github.io/mediapipe/solutions/selfie_segmentation.html" class="nav-list-link">Selfie Segmentation</a></li><li class="nav-list-item "><a href="https://google.github.io/mediapipe/solutions/hair_segmentation.html" class="nav-list-link">Hair Segmentation</a></li><li class="nav-list-item "><a href="https://google.github.io/mediapipe/solutions/object_detection.html" class="nav-list-link">Object Detection</a></li><li class="nav-list-item "><a href="https://google.github.io/mediapipe/solutions/box_tracking.html" class="nav-list-link">Box Tracking</a></li><li class="nav-list-item "><a href="https://google.github.io/mediapipe/solutions/instant_motion_tracking.html" class="nav-list-link">Instant Motion Tracking</a></li><li class="nav-list-item "><a href="https://google.github.io/mediapipe/solutions/objectron.html" class="nav-list-link">Objectron (3D Object Detection)</a></li><li class="nav-list-item "><a href="https://google.github.io/mediapipe/solutions/knift.html" class="nav-list-link">KNIFT (Template-based Feature Matching)</a></li><li class="nav-list-item "><a href="https://google.github.io/mediapipe/solutions/autoflip.html" class="nav-list-link">AutoFlip (Saliency-aware Video Cropping)</a></li><li class="nav-list-item "><a href="https://google.github.io/mediapipe/solutions/media_sequence.html" class="nav-list-link">Dataset Preparation with MediaSequence</a></li><li class="nav-list-item "><a href="https://google.github.io/mediapipe/solutions/youtube_8m.html" class="nav-list-link">YouTube-8M Feature Extraction and Model Inference</a></li><li class="nav-list-item "><a href="https://google.github.io/mediapipe/solutions/models.html" class="nav-list-link">Models and Model Cards</a></li></ul></li><li class="nav-list-item"><a href="https://google.github.io/mediapipe/solutions/hands.html#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="https://google.github.io/mediapipe/tools/tools.html" class="nav-list-link">Tools</a><ul class="nav-list "><li class="nav-list-item "><a href="https://google.github.io/mediapipe/tools/visualizer.html" class="nav-list-link">Visualizer</a></li><li class="nav-list-item "><a href="https://google.github.io/mediapipe/tools/tracing_and_profiling.html" class="nav-list-link">Tracing and Profiling</a></li><li class="nav-list-item "><a href="https://google.github.io/mediapipe/tools/performance_benchmarking.html" class="nav-list-link">Performance Benchmarking</a></li></ul></li><li class="nav-list-item"><a href="https://google.github.io/mediapipe/solutions/hands.html#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="https://google.github.io/mediapipe/framework_concepts/framework_concepts.html" class="nav-list-link">Framework Concepts</a><ul class="nav-list "><li class="nav-list-item "><a href="https://google.github.io/mediapipe/framework_concepts/calculators.html" class="nav-list-link">Calculators</a></li><li class="nav-list-item "><a href="https://google.github.io/mediapipe/framework_concepts/graphs.html" class="nav-list-link">Graphs</a></li><li class="nav-list-item "><a href="https://google.github.io/mediapipe/framework_concepts/packets.html" class="nav-list-link">Packets</a></li><li class="nav-list-item "><a href="https://google.github.io/mediapipe/framework_concepts/synchronization.html" class="nav-list-link">Synchronization</a></li><li class="nav-list-item "><a href="https://google.github.io/mediapipe/framework_concepts/gpu.html" class="nav-list-link">GPU</a></li><li class="nav-list-item "><a href="https://google.github.io/mediapipe/framework_concepts/realtime_streams.html" class="nav-list-link">Real-time Streams</a></li></ul></li></ul> </nav> <footer class="site-footer"> This site uses <a href="https://github.com/just-the-docs/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll. </footer> </div> <div class="main" id="top"> <div id="main-header" class="main-header"> <div class="search"> <div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search mediapipe" aria-label="Search mediapipe" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label> </div> <div id="search-results" class="search-results"></div> </div> <nav aria-label="Auxiliary" class="aux-nav"> <ul class="aux-nav-list"> <li class="aux-nav-list-item"> <a href="https://github.com/google/mediapipe" class="site-button"> MediaPipe on GitHub </a> </li> </ul> </nav> </div> <div id="main-content-wrap" class="main-content-wrap"> <nav aria-label="Breadcrumb" class="breadcrumb-nav"> <ol class="breadcrumb-nav-list"> <li class="breadcrumb-nav-list-item"><a href="https://google.github.io/mediapipe/solutions/solutions.html">Solutions</a></li> <li class="breadcrumb-nav-list-item"><span>Hands</span></li> </ol> </nav> <div id="main-content" class="main-content" role="main"> <h1 class="no_toc" id="mediapipe-hands"> <a href="https://google.github.io/mediapipe/solutions/hands.html#mediapipe-hands" class="anchor-heading" aria-labelledby="mediapipe-hands"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> MediaPipe Hands </h1> <details close=""> <summary class="text-delta"> Table of contents </summary> <ol id="markdown-toc"> <li><a href="https://google.github.io/mediapipe/solutions/hands.html#overview" id="markdown-toc-overview">Overview</a></li> <li><a href="https://google.github.io/mediapipe/solutions/hands.html#ml-pipeline" id="markdown-toc-ml-pipeline">ML Pipeline</a></li> <li><a href="https://google.github.io/mediapipe/solutions/hands.html#models" id="markdown-toc-models">Models</a> <ol> <li><a href="https://google.github.io/mediapipe/solutions/hands.html#palm-detection-model" id="markdown-toc-palm-detection-model">Palm Detection Model</a></li> <li><a href="https://google.github.io/mediapipe/solutions/hands.html#hand-landmark-model" id="markdown-toc-hand-landmark-model">Hand Landmark Model</a></li> </ol> </li> <li><a href="https://google.github.io/mediapipe/solutions/hands.html#solution-apis" id="markdown-toc-solution-apis">Solution APIs</a> <ol> <li><a href="https://google.github.io/mediapipe/solutions/hands.html#configuration-options" id="markdown-toc-configuration-options">Configuration Options</a> <ol> <li><a href="https://google.github.io/mediapipe/solutions/hands.html#static_image_mode" id="markdown-toc-static_image_mode">static_image_mode</a></li> <li><a href="https://google.github.io/mediapipe/solutions/hands.html#max_num_hands" id="markdown-toc-max_num_hands">max_num_hands</a></li> <li><a href="https://google.github.io/mediapipe/solutions/hands.html#model_complexity" id="markdown-toc-model_complexity">model_complexity</a></li> <li><a href="https://google.github.io/mediapipe/solutions/hands.html#min_detection_confidence" id="markdown-toc-min_detection_confidence">min_detection_confidence</a></li> <li><a href="https://google.github.io/mediapipe/solutions/hands.html#min_tracking_confidence" id="markdown-toc-min_tracking_confidence">min_tracking_confidence:</a></li> </ol> </li> <li><a href="https://google.github.io/mediapipe/solutions/hands.html#output" id="markdown-toc-output">Output</a> <ol> <li><a href="https://google.github.io/mediapipe/solutions/hands.html#multi_hand_landmarks" id="markdown-toc-multi_hand_landmarks">multi_hand_landmarks</a></li> <li><a href="https://google.github.io/mediapipe/solutions/hands.html#multi_hand_world_landmarks" id="markdown-toc-multi_hand_world_landmarks">multi_hand_world_landmarks</a></li> <li><a href="https://google.github.io/mediapipe/solutions/hands.html#multi_handedness" id="markdown-toc-multi_handedness">multi_handedness</a></li> </ol> </li> <li><a href="https://google.github.io/mediapipe/solutions/hands.html#python-solution-api" id="markdown-toc-python-solution-api">Python Solution API</a></li> <li><a href="https://google.github.io/mediapipe/solutions/hands.html#javascript-solution-api" id="markdown-toc-javascript-solution-api">JavaScript Solution API</a></li> <li><a href="https://google.github.io/mediapipe/solutions/hands.html#android-solution-api" id="markdown-toc-android-solution-api">Android Solution API</a> <ol> <li><a href="https://google.github.io/mediapipe/solutions/hands.html#camera-input" id="markdown-toc-camera-input">Camera Input</a></li> <li><a href="https://google.github.io/mediapipe/solutions/hands.html#image-input" id="markdown-toc-image-input">Image Input</a></li> <li><a href="https://google.github.io/mediapipe/solutions/hands.html#video-input" id="markdown-toc-video-input">Video Input</a></li> </ol> </li> </ol> </li> <li><a href="https://google.github.io/mediapipe/solutions/hands.html#example-apps" id="markdown-toc-example-apps">Example Apps</a> <ol> <li><a href="https://google.github.io/mediapipe/solutions/hands.html#mobile" id="markdown-toc-mobile">Mobile</a> <ol> <li><a href="https://google.github.io/mediapipe/solutions/hands.html#main-example" id="markdown-toc-main-example">Main Example</a></li> <li><a href="https://google.github.io/mediapipe/solutions/hands.html#palmhand-detection-only-no-landmarks" id="markdown-toc-palmhand-detection-only-no-landmarks">Palm/Hand Detection Only (no landmarks)</a></li> </ol> </li> <li><a href="https://google.github.io/mediapipe/solutions/hands.html#desktop" id="markdown-toc-desktop">Desktop</a></li> </ol> </li> <li><a href="https://google.github.io/mediapipe/solutions/hands.html#resources" id="markdown-toc-resources">Resources</a></li> </ol> </details><hr> <h2 id="overview"> <a href="https://google.github.io/mediapipe/solutions/hands.html#overview" class="anchor-heading" aria-labelledby="overview"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Overview </h2> <p>The ability to perceive the shape and motion of hands can be a vital component in improving the user experience across a variety of technological domains and platforms. For example, it can form the basis for sign language understanding and hand gesture control, and can also enable the overlay of digital content and information on top of the physical world in augmented reality. While coming naturally to people, robust real-time hand perception is a decidedly challenging computer vision task, as hands often occlude themselves or each other (e.g. finger/palm occlusions and hand shakes) and lack high contrast patterns.</p> <p>MediaPipe Hands is a high-fidelity hand and finger tracking solution. It employs machine learning (ML) to infer 21 3D landmarks of a hand from just a single frame. Whereas current state-of-the-art approaches rely primarily on powerful desktop environments for inference, our method achieves real-time performance on a mobile phone, and even scales to multiple hands. We hope that providing this hand perception functionality to the wider research and development community will result in an emergence of creative use cases, stimulating new applications and new research avenues.</p> <div class="table-wrapper"><table> <thead> <tr> <th style="text-align: center"><img src="./Hands_files/hand_tracking_3d_android_gpu.gif" alt="hand_tracking_3d_android_gpu.gif"></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Fig 1. Tracked 3D hand landmarks are represented by dots in different shades, with the brighter ones denoting landmarks closer to the camera.</em></td> </tr> </tbody> </table></div> <h2 id="ml-pipeline"> <a href="https://google.github.io/mediapipe/solutions/hands.html#ml-pipeline" class="anchor-heading" aria-labelledby="ml-pipeline"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> ML Pipeline </h2> <p>MediaPipe Hands utilizes an ML pipeline consisting of multiple models working together: A palm detection model that operates on the full image and returns an oriented hand bounding box. A hand landmark model that operates on the cropped image region defined by the palm detector and returns high-fidelity 3D hand keypoints. This strategy is similar to that employed in our <a href="https://google.github.io/mediapipe/solutions/face_mesh.html">MediaPipe Face Mesh</a> solution, which uses a face detector together with a face landmark model.</p> <p>Providing the accurately cropped hand image to the hand landmark model drastically reduces the need for data augmentation (e.g. rotations, translation and scale) and instead allows the network to dedicate most of its capacity towards coordinate prediction accuracy. In addition, in our pipeline the crops can also be generated based on the hand landmarks identified in the previous frame, and only when the landmark model could no longer identify hand presence is palm detection invoked to relocalize the hand.</p> <p>The pipeline is implemented as a MediaPipe <a href="https://github.com/google/mediapipe/tree/master/mediapipe/graphs/hand_tracking/hand_tracking_mobile.pbtxt">graph</a> that uses a <a href="https://github.com/google/mediapipe/tree/master/mediapipe/modules/hand_landmark/hand_landmark_tracking_gpu.pbtxt">hand landmark tracking subgraph</a> from the <a href="https://github.com/google/mediapipe/tree/master/mediapipe/modules/hand_landmark">hand landmark module</a>, and renders using a dedicated <a href="https://github.com/google/mediapipe/tree/master/mediapipe/graphs/hand_tracking/subgraphs/hand_renderer_gpu.pbtxt">hand renderer subgraph</a>. The <a href="https://github.com/google/mediapipe/tree/master/mediapipe/modules/hand_landmark/hand_landmark_tracking_gpu.pbtxt">hand landmark tracking subgraph</a> internally uses a <a href="https://github.com/google/mediapipe/tree/master/mediapipe/modules/hand_landmark/hand_landmark_gpu.pbtxt">hand landmark subgraph</a> from the same module and a <a href="https://github.com/google/mediapipe/tree/master/mediapipe/modules/palm_detection/palm_detection_gpu.pbtxt">palm detection subgraph</a> from the <a href="https://github.com/google/mediapipe/tree/master/mediapipe/modules/palm_detection">palm detection module</a>.</p> <p>Note: To visualize a graph, copy the graph and paste it into <a href="https://viz.mediapipe.dev/">MediaPipe Visualizer</a>. For more information on how to visualize its associated subgraphs, please see <a href="https://google.github.io/mediapipe/tools/visualizer.html">visualizer documentation</a>.</p> <h2 id="models"> <a href="https://google.github.io/mediapipe/solutions/hands.html#models" class="anchor-heading" aria-labelledby="models"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Models </h2> <h3 id="palm-detection-model"> <a href="https://google.github.io/mediapipe/solutions/hands.html#palm-detection-model" class="anchor-heading" aria-labelledby="palm-detection-model"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Palm Detection Model </h3> <p>To detect initial hand locations, we designed a <a href="https://arxiv.org/abs/1512.02325">single-shot detector</a> model optimized for mobile real-time uses in a manner similar to the face detection model in <a href="https://google.github.io/mediapipe/solutions/face_mesh.html">MediaPipe Face Mesh</a>. Detecting hands is a decidedly complex task: our <a href="https://github.com/google/mediapipe/tree/master/mediapipe/modules/palm_detection/palm_detection_lite.tflite">lite model</a> and <a href="https://github.com/google/mediapipe/tree/master/mediapipe/modules/palm_detection/palm_detection_full.tflite">full model</a> have to work across a variety of hand sizes with a large scale span (~20x) relative to the image frame and be able to detect occluded and self-occluded hands. Whereas faces have high contrast patterns, e.g., in the eye and mouth region, the lack of such features in hands makes it comparatively difficult to detect them reliably from their visual features alone. Instead, providing additional context, like arm, body, or person features, aids accurate hand localization.</p> <p>Our method addresses the above challenges using different strategies. First, we train a palm detector instead of a hand detector, since estimating bounding boxes of rigid objects like palms and fists is significantly simpler than detecting hands with articulated fingers. In addition, as palms are smaller objects, the non-maximum suppression algorithm works well even for two-hand self-occlusion cases, like handshakes. Moreover, palms can be modelled using square bounding boxes (anchors in ML terminology) ignoring other aspect ratios, and therefore reducing the number of anchors by a factor of 3-5. Second, an encoder-decoder feature extractor is used for bigger scene context awareness even for small objects (similar to the RetinaNet approach). Lastly, we minimize the focal loss during training to support a large amount of anchors resulting from the high scale variance.</p> <p>With the above techniques, we achieve an average precision of 95.7% in palm detection. Using a regular cross entropy loss and no decoder gives a baseline of just 86.22%.</p> <h3 id="hand-landmark-model"> <a href="https://google.github.io/mediapipe/solutions/hands.html#hand-landmark-model" class="anchor-heading" aria-labelledby="hand-landmark-model"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Hand Landmark Model </h3> <p>After the palm detection over the whole image our subsequent hand landmark <a href="https://github.com/google/mediapipe/tree/master/mediapipe/modules/hand_landmark/hand_landmark_full.tflite">model</a> performs precise keypoint localization of 21 3D hand-knuckle coordinates inside the detected hand regions via regression, that is direct coordinate prediction. The model learns a consistent internal hand pose representation and is robust even to partially visible hands and self-occlusions.</p> <p>To obtain ground truth data, we have manually annotated ~30K real-world images with 21 3D coordinates, as shown below (we take Z-value from image depth map, if it exists per corresponding coordinate). To better cover the possible hand poses and provide additional supervision on the nature of hand geometry, we also render a high-quality synthetic hand model over various backgrounds and map it to the corresponding 3D coordinates.</p> <div class="table-wrapper"><table> <thead> <tr> <th style="text-align: center"><img src="./Hands_files/hand_landmarks.png" alt="hand_landmarks.png"></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Fig 2. 21 hand landmarks.</em></td> </tr> </tbody> </table></div> <div class="table-wrapper"><table> <thead> <tr> <th style="text-align: center"><img src="./Hands_files/hand_crops.png" alt="hand_crops.png"></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Fig 3. Top: Aligned hand crops passed to the tracking network with ground truth annotation. Bottom: Rendered synthetic hand images with ground truth annotation.</em></td> </tr> </tbody> </table></div> <h2 id="solution-apis"> <a href="https://google.github.io/mediapipe/solutions/hands.html#solution-apis" class="anchor-heading" aria-labelledby="solution-apis"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Solution APIs </h2> <h3 id="configuration-options"> <a href="https://google.github.io/mediapipe/solutions/hands.html#configuration-options" class="anchor-heading" aria-labelledby="configuration-options"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Configuration Options </h3> <p>Naming style and availability may differ slightly across platforms/languages.</p> <h4 id="static_image_mode"> <a href="https://google.github.io/mediapipe/solutions/hands.html#static_image_mode" class="anchor-heading" aria-labelledby="static_image_mode"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> static_image_mode </h4> <p>If set to <code class="language-plaintext highlighter-rouge">false</code>, the solution treats the input images as a video stream. It will try to detect hands in the first input images, and upon a successful detection further localizes the hand landmarks. In subsequent images, once all <a href="https://google.github.io/mediapipe/solutions/hands.html#max_num_hands">max_num_hands</a> hands are detected and the corresponding hand landmarks are localized, it simply tracks those landmarks without invoking another detection until it loses track of any of the hands. This reduces latency and is ideal for processing video frames. If set to <code class="language-plaintext highlighter-rouge">true</code>, hand detection runs on every input image, ideal for processing a batch of static, possibly unrelated, images. Default to <code class="language-plaintext highlighter-rouge">false</code>.</p> <h4 id="max_num_hands"> <a href="https://google.github.io/mediapipe/solutions/hands.html#max_num_hands" class="anchor-heading" aria-labelledby="max_num_hands"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> max_num_hands </h4> <p>Maximum number of hands to detect. Default to <code class="language-plaintext highlighter-rouge">2</code>.</p> <h4 id="model_complexity"> <a href="https://google.github.io/mediapipe/solutions/hands.html#model_complexity" class="anchor-heading" aria-labelledby="model_complexity"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> model_complexity </h4> <p>Complexity of the hand landmark model: <code class="language-plaintext highlighter-rouge">0</code> or <code class="language-plaintext highlighter-rouge">1</code>. Landmark accuracy as well as inference latency generally go up with the model complexity. Default to <code class="language-plaintext highlighter-rouge">1</code>.</p> <h4 id="min_detection_confidence"> <a href="https://google.github.io/mediapipe/solutions/hands.html#min_detection_confidence" class="anchor-heading" aria-labelledby="min_detection_confidence"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> min_detection_confidence </h4> <p>Minimum confidence value (<code class="language-plaintext highlighter-rouge">[0.0, 1.0]</code>) from the hand detection model for the detection to be considered successful. Default to <code class="language-plaintext highlighter-rouge">0.5</code>.</p> <h4 id="min_tracking_confidence"> <a href="https://google.github.io/mediapipe/solutions/hands.html#min_tracking_confidence" class="anchor-heading" aria-labelledby="min_tracking_confidence"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> min_tracking_confidence: </h4> <p>Minimum confidence value (<code class="language-plaintext highlighter-rouge">[0.0, 1.0]</code>) from the landmark-tracking model for the hand landmarks to be considered tracked successfully, or otherwise hand detection will be invoked automatically on the next input image. Setting it to a higher value can increase robustness of the solution, at the expense of a higher latency. Ignored if <a href="https://google.github.io/mediapipe/solutions/hands.html#static_image_mode">static_image_mode</a> is <code class="language-plaintext highlighter-rouge">true</code>, where hand detection simply runs on every image. Default to <code class="language-plaintext highlighter-rouge">0.5</code>.</p> <h3 id="output"> <a href="https://google.github.io/mediapipe/solutions/hands.html#output" class="anchor-heading" aria-labelledby="output"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Output </h3> <p>Naming style may differ slightly across platforms/languages.</p> <h4 id="multi_hand_landmarks"> <a href="https://google.github.io/mediapipe/solutions/hands.html#multi_hand_landmarks" class="anchor-heading" aria-labelledby="multi_hand_landmarks"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> multi_hand_landmarks </h4> <p>Collection of detected/tracked hands, where each hand is represented as a list of 21 hand landmarks and each landmark is composed of <code class="language-plaintext highlighter-rouge">x</code>, <code class="language-plaintext highlighter-rouge">y</code> and <code class="language-plaintext highlighter-rouge">z</code>. <code class="language-plaintext highlighter-rouge">x</code> and <code class="language-plaintext highlighter-rouge">y</code> are normalized to <code class="language-plaintext highlighter-rouge">[0.0, 1.0]</code> by the image width and height respectively. <code class="language-plaintext highlighter-rouge">z</code> represents the landmark depth with the depth at the wrist being the origin, and the smaller the value the closer the landmark is to the camera. The magnitude of <code class="language-plaintext highlighter-rouge">z</code> uses roughly the same scale as <code class="language-plaintext highlighter-rouge">x</code>.</p> <h4 id="multi_hand_world_landmarks"> <a href="https://google.github.io/mediapipe/solutions/hands.html#multi_hand_world_landmarks" class="anchor-heading" aria-labelledby="multi_hand_world_landmarks"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> multi_hand_world_landmarks </h4> <p>Collection of detected/tracked hands, where each hand is represented as a list of 21 hand landmarks in world coordinates. Each landmark is composed of <code class="language-plaintext highlighter-rouge">x</code>, <code class="language-plaintext highlighter-rouge">y</code> and <code class="language-plaintext highlighter-rouge">z</code>: real-world 3D coordinates in meters with the origin at the hand’s approximate geometric center.</p> <h4 id="multi_handedness"> <a href="https://google.github.io/mediapipe/solutions/hands.html#multi_handedness" class="anchor-heading" aria-labelledby="multi_handedness"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> multi_handedness </h4> <p>Collection of handedness of the detected/tracked hands (i.e. is it a left or right hand). Each hand is composed of <code class="language-plaintext highlighter-rouge">label</code> and <code class="language-plaintext highlighter-rouge">score</code>. <code class="language-plaintext highlighter-rouge">label</code> is a string of value either <code class="language-plaintext highlighter-rouge">"Left"</code> or <code class="language-plaintext highlighter-rouge">"Right"</code>. <code class="language-plaintext highlighter-rouge">score</code> is the estimated probability of the predicted handedness and is always greater than or equal to <code class="language-plaintext highlighter-rouge">0.5</code> (and the opposite handedness has an estimated probability of <code class="language-plaintext highlighter-rouge">1 - score</code>).</p> <p>Note that handedness is determined assuming the input image is mirrored, i.e., taken with a front-facing/selfie camera with images flipped horizontally. If it is not the case, please swap the handedness output in the application.</p> <h3 id="python-solution-api"> <a href="https://google.github.io/mediapipe/solutions/hands.html#python-solution-api" class="anchor-heading" aria-labelledby="python-solution-api"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Python Solution API </h3> <p>Please first follow general <a href="https://google.github.io/mediapipe/getting_started/python.html">instructions</a> to install MediaPipe Python package, then learn more in the companion <a href="https://google.github.io/mediapipe/solutions/hands.html#resources">Python Colab</a> and the usage example below.</p> <p>Supported configuration options:</p> <ul> <li><a href="https://google.github.io/mediapipe/solutions/hands.html#static_image_mode">static_image_mode</a></li> <li><a href="https://google.github.io/mediapipe/solutions/hands.html#max_num_hands">max_num_hands</a></li> <li><a href="https://google.github.io/mediapipe/solutions/hands.html#model_complexity">model_complexity</a></li> <li><a href="https://google.github.io/mediapipe/solutions/hands.html#min_detection_confidence">min_detection_confidence</a></li> <li><a href="https://google.github.io/mediapipe/solutions/hands.html#min_tracking_confidence">min_tracking_confidence</a></li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">import</span> <span class="nn">mediapipe</span> <span class="k">as</span> <span class="n">mp</span>
<span class="n">mp_drawing</span> <span class="o">=</span> <span class="n">mp</span><span class="p">.</span><span class="n">solutions</span><span class="p">.</span><span class="n">drawing_utils</span>
<span class="n">mp_drawing_styles</span> <span class="o">=</span> <span class="n">mp</span><span class="p">.</span><span class="n">solutions</span><span class="p">.</span><span class="n">drawing_styles</span>
<span class="n">mp_hands</span> <span class="o">=</span> <span class="n">mp</span><span class="p">.</span><span class="n">solutions</span><span class="p">.</span><span class="n">hands</span>

<span class="c1"># For static images:
</span><span class="n">IMAGE_FILES</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">with</span> <span class="n">mp_hands</span><span class="p">.</span><span class="n">Hands</span><span class="p">(</span>
    <span class="n">static_image_mode</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">max_num_hands</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">min_detection_confidence</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span> <span class="k">as</span> <span class="n">hands</span><span class="p">:</span>
  <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="nb">file</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">IMAGE_FILES</span><span class="p">):</span>
    <span class="c1"># Read an image, flip it around y-axis for correct handedness output (see
</span>    <span class="c1"># above).
</span>    <span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">flip</span><span class="p">(</span><span class="n">cv2</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="nb">file</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
    <span class="c1"># Convert the BGR image to RGB before processing.
</span>    <span class="n">results</span> <span class="o">=</span> <span class="n">hands</span><span class="p">.</span><span class="n">process</span><span class="p">(</span><span class="n">cv2</span><span class="p">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">COLOR_BGR2RGB</span><span class="p">))</span>

    <span class="c1"># Print handedness and draw hand landmarks on the image.
</span>    <span class="k">print</span><span class="p">(</span><span class="s">'Handedness:'</span><span class="p">,</span> <span class="n">results</span><span class="p">.</span><span class="n">multi_handedness</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">results</span><span class="p">.</span><span class="n">multi_hand_landmarks</span><span class="p">:</span>
      <span class="k">continue</span>
    <span class="n">image_height</span><span class="p">,</span> <span class="n">image_width</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">image</span><span class="p">.</span><span class="n">shape</span>
    <span class="n">annotated_image</span> <span class="o">=</span> <span class="n">image</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">hand_landmarks</span> <span class="ow">in</span> <span class="n">results</span><span class="p">.</span><span class="n">multi_hand_landmarks</span><span class="p">:</span>
      <span class="k">print</span><span class="p">(</span><span class="s">'hand_landmarks:'</span><span class="p">,</span> <span class="n">hand_landmarks</span><span class="p">)</span>
      <span class="k">print</span><span class="p">(</span>
          <span class="sa">f</span><span class="s">'Index finger tip coordinates: ('</span><span class="p">,</span>
          <span class="sa">f</span><span class="s">'</span><span class="si">{</span><span class="n">hand_landmarks</span><span class="p">.</span><span class="n">landmark</span><span class="p">[</span><span class="n">mp_hands</span><span class="p">.</span><span class="n">HandLandmark</span><span class="p">.</span><span class="n">INDEX_FINGER_TIP</span><span class="p">].</span><span class="n">x</span> <span class="o">*</span> <span class="n">image_width</span><span class="si">}</span><span class="s">, '</span>
          <span class="sa">f</span><span class="s">'</span><span class="si">{</span><span class="n">hand_landmarks</span><span class="p">.</span><span class="n">landmark</span><span class="p">[</span><span class="n">mp_hands</span><span class="p">.</span><span class="n">HandLandmark</span><span class="p">.</span><span class="n">INDEX_FINGER_TIP</span><span class="p">].</span><span class="n">y</span> <span class="o">*</span> <span class="n">image_height</span><span class="si">}</span><span class="s">)'</span>
      <span class="p">)</span>
      <span class="n">mp_drawing</span><span class="p">.</span><span class="n">draw_landmarks</span><span class="p">(</span>
          <span class="n">annotated_image</span><span class="p">,</span>
          <span class="n">hand_landmarks</span><span class="p">,</span>
          <span class="n">mp_hands</span><span class="p">.</span><span class="n">HAND_CONNECTIONS</span><span class="p">,</span>
          <span class="n">mp_drawing_styles</span><span class="p">.</span><span class="n">get_default_hand_landmarks_style</span><span class="p">(),</span>
          <span class="n">mp_drawing_styles</span><span class="p">.</span><span class="n">get_default_hand_connections_style</span><span class="p">())</span>
    <span class="n">cv2</span><span class="p">.</span><span class="n">imwrite</span><span class="p">(</span>
        <span class="s">'/tmp/annotated_image'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span> <span class="o">+</span> <span class="s">'.png'</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">flip</span><span class="p">(</span><span class="n">annotated_image</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="c1"># Draw hand world landmarks.
</span>    <span class="k">if</span> <span class="ow">not</span> <span class="n">results</span><span class="p">.</span><span class="n">multi_hand_world_landmarks</span><span class="p">:</span>
      <span class="k">continue</span>
    <span class="k">for</span> <span class="n">hand_world_landmarks</span> <span class="ow">in</span> <span class="n">results</span><span class="p">.</span><span class="n">multi_hand_world_landmarks</span><span class="p">:</span>
      <span class="n">mp_drawing</span><span class="p">.</span><span class="n">plot_landmarks</span><span class="p">(</span>
        <span class="n">hand_world_landmarks</span><span class="p">,</span> <span class="n">mp_hands</span><span class="p">.</span><span class="n">HAND_CONNECTIONS</span><span class="p">,</span> <span class="n">azimuth</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="c1"># For webcam input:
</span><span class="n">cap</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">VideoCapture</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="k">with</span> <span class="n">mp_hands</span><span class="p">.</span><span class="n">Hands</span><span class="p">(</span>
    <span class="n">model_complexity</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">min_detection_confidence</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">min_tracking_confidence</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span> <span class="k">as</span> <span class="n">hands</span><span class="p">:</span>
  <span class="k">while</span> <span class="n">cap</span><span class="p">.</span><span class="n">isOpened</span><span class="p">():</span>
    <span class="n">success</span><span class="p">,</span> <span class="n">image</span> <span class="o">=</span> <span class="n">cap</span><span class="p">.</span><span class="n">read</span><span class="p">()</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">success</span><span class="p">:</span>
      <span class="k">print</span><span class="p">(</span><span class="s">"Ignoring empty camera frame."</span><span class="p">)</span>
      <span class="c1"># If loading a video, use 'break' instead of 'continue'.
</span>      <span class="k">continue</span>

    <span class="c1"># To improve performance, optionally mark the image as not writeable to
</span>    <span class="c1"># pass by reference.
</span>    <span class="n">image</span><span class="p">.</span><span class="n">flags</span><span class="p">.</span><span class="n">writeable</span> <span class="o">=</span> <span class="bp">False</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">COLOR_BGR2RGB</span><span class="p">)</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">hands</span><span class="p">.</span><span class="n">process</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

    <span class="c1"># Draw the hand annotations on the image.
</span>    <span class="n">image</span><span class="p">.</span><span class="n">flags</span><span class="p">.</span><span class="n">writeable</span> <span class="o">=</span> <span class="bp">True</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">COLOR_RGB2BGR</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">results</span><span class="p">.</span><span class="n">multi_hand_landmarks</span><span class="p">:</span>
      <span class="k">for</span> <span class="n">hand_landmarks</span> <span class="ow">in</span> <span class="n">results</span><span class="p">.</span><span class="n">multi_hand_landmarks</span><span class="p">:</span>
        <span class="n">mp_drawing</span><span class="p">.</span><span class="n">draw_landmarks</span><span class="p">(</span>
            <span class="n">image</span><span class="p">,</span>
            <span class="n">hand_landmarks</span><span class="p">,</span>
            <span class="n">mp_hands</span><span class="p">.</span><span class="n">HAND_CONNECTIONS</span><span class="p">,</span>
            <span class="n">mp_drawing_styles</span><span class="p">.</span><span class="n">get_default_hand_landmarks_style</span><span class="p">(),</span>
            <span class="n">mp_drawing_styles</span><span class="p">.</span><span class="n">get_default_hand_connections_style</span><span class="p">())</span>
    <span class="c1"># Flip the image horizontally for a selfie-view display.
</span>    <span class="n">cv2</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="s">'MediaPipe Hands'</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">flip</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">cv2</span><span class="p">.</span><span class="n">waitKey</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span> <span class="o">&amp;</span> <span class="mh">0xFF</span> <span class="o">==</span> <span class="mi">27</span><span class="p">:</span>
      <span class="k">break</span>
<span class="n">cap</span><span class="p">.</span><span class="n">release</span><span class="p">()</span>
</code></pre></div></div> <h3 id="javascript-solution-api"> <a href="https://google.github.io/mediapipe/solutions/hands.html#javascript-solution-api" class="anchor-heading" aria-labelledby="javascript-solution-api"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> JavaScript Solution API </h3> <p>Please first see general <a href="https://google.github.io/mediapipe/getting_started/javascript.html">introduction</a> on MediaPipe in JavaScript, then learn more in the companion <a href="https://google.github.io/mediapipe/solutions/hands.html#resources">web demo</a> and a [fun application], and the following usage example.</p> <p>Supported configuration options:</p> <ul> <li><a href="https://google.github.io/mediapipe/solutions/hands.html#max_num_hands">maxNumHands</a></li> <li><a href="https://google.github.io/mediapipe/solutions/hands.html#model_complexity">modelComplexity</a></li> <li><a href="https://google.github.io/mediapipe/solutions/hands.html#min_detection_confidence">minDetectionConfidence</a></li> <li><a href="https://google.github.io/mediapipe/solutions/hands.html#min_tracking_confidence">minTrackingConfidence</a></li> </ul> <div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">&lt;!DOCTYPE html&gt;</span>
<span class="nt">&lt;html&gt;</span>
<span class="nt">&lt;head&gt;</span>
  <span class="nt">&lt;meta</span> <span class="na">charset=</span><span class="s">"utf-8"</span><span class="nt">&gt;</span>
  <span class="nt">&lt;script </span><span class="na">src=</span><span class="s">"https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"</span> <span class="na">crossorigin=</span><span class="s">"anonymous"</span><span class="nt">&gt;&lt;/script&gt;</span>
  <span class="nt">&lt;script </span><span class="na">src=</span><span class="s">"https://cdn.jsdelivr.net/npm/@mediapipe/control_utils/control_utils.js"</span> <span class="na">crossorigin=</span><span class="s">"anonymous"</span><span class="nt">&gt;&lt;/script&gt;</span>
  <span class="nt">&lt;script </span><span class="na">src=</span><span class="s">"https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"</span> <span class="na">crossorigin=</span><span class="s">"anonymous"</span><span class="nt">&gt;&lt;/script&gt;</span>
  <span class="nt">&lt;script </span><span class="na">src=</span><span class="s">"https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"</span> <span class="na">crossorigin=</span><span class="s">"anonymous"</span><span class="nt">&gt;&lt;/script&gt;</span>
<span class="nt">&lt;/head&gt;</span>

<span class="nt">&lt;body&gt;</span>
  <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"container"</span><span class="nt">&gt;</span>
    <span class="nt">&lt;video</span> <span class="na">class=</span><span class="s">"input_video"</span><span class="nt">&gt;&lt;/video&gt;</span>
    <span class="nt">&lt;canvas</span> <span class="na">class=</span><span class="s">"output_canvas"</span> <span class="na">width=</span><span class="s">"1280px"</span> <span class="na">height=</span><span class="s">"720px"</span><span class="nt">&gt;&lt;/canvas&gt;</span>
  <span class="nt">&lt;/div&gt;</span>
<span class="nt">&lt;/body&gt;</span>
<span class="nt">&lt;/html&gt;</span>
</code></pre></div></div> <div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&lt;</span><span class="nx">script</span> <span class="nx">type</span><span class="o">=</span><span class="dl">"</span><span class="s2">module</span><span class="dl">"</span><span class="o">&gt;</span>
<span class="kd">const</span> <span class="nx">videoElement</span> <span class="o">=</span> <span class="nb">document</span><span class="p">.</span><span class="nx">getElementsByClassName</span><span class="p">(</span><span class="dl">'</span><span class="s1">input_video</span><span class="dl">'</span><span class="p">)[</span><span class="mi">0</span><span class="p">];</span>
<span class="kd">const</span> <span class="nx">canvasElement</span> <span class="o">=</span> <span class="nb">document</span><span class="p">.</span><span class="nx">getElementsByClassName</span><span class="p">(</span><span class="dl">'</span><span class="s1">output_canvas</span><span class="dl">'</span><span class="p">)[</span><span class="mi">0</span><span class="p">];</span>
<span class="kd">const</span> <span class="nx">canvasCtx</span> <span class="o">=</span> <span class="nx">canvasElement</span><span class="p">.</span><span class="nx">getContext</span><span class="p">(</span><span class="dl">'</span><span class="s1">2d</span><span class="dl">'</span><span class="p">);</span>

<span class="kd">function</span> <span class="nx">onResults</span><span class="p">(</span><span class="nx">results</span><span class="p">)</span> <span class="p">{</span>
  <span class="nx">canvasCtx</span><span class="p">.</span><span class="nx">save</span><span class="p">();</span>
  <span class="nx">canvasCtx</span><span class="p">.</span><span class="nx">clearRect</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="nx">canvasElement</span><span class="p">.</span><span class="nx">width</span><span class="p">,</span> <span class="nx">canvasElement</span><span class="p">.</span><span class="nx">height</span><span class="p">);</span>
  <span class="nx">canvasCtx</span><span class="p">.</span><span class="nx">drawImage</span><span class="p">(</span>
      <span class="nx">results</span><span class="p">.</span><span class="nx">image</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="nx">canvasElement</span><span class="p">.</span><span class="nx">width</span><span class="p">,</span> <span class="nx">canvasElement</span><span class="p">.</span><span class="nx">height</span><span class="p">);</span>
  <span class="k">if</span> <span class="p">(</span><span class="nx">results</span><span class="p">.</span><span class="nx">multiHandLandmarks</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">for</span> <span class="p">(</span><span class="kd">const</span> <span class="nx">landmarks</span> <span class="k">of</span> <span class="nx">results</span><span class="p">.</span><span class="nx">multiHandLandmarks</span><span class="p">)</span> <span class="p">{</span>
      <span class="nx">drawConnectors</span><span class="p">(</span><span class="nx">canvasCtx</span><span class="p">,</span> <span class="nx">landmarks</span><span class="p">,</span> <span class="nx">HAND_CONNECTIONS</span><span class="p">,</span>
                     <span class="p">{</span><span class="na">color</span><span class="p">:</span> <span class="dl">'</span><span class="s1">#00FF00</span><span class="dl">'</span><span class="p">,</span> <span class="na">lineWidth</span><span class="p">:</span> <span class="mi">5</span><span class="p">});</span>
      <span class="nx">drawLandmarks</span><span class="p">(</span><span class="nx">canvasCtx</span><span class="p">,</span> <span class="nx">landmarks</span><span class="p">,</span> <span class="p">{</span><span class="na">color</span><span class="p">:</span> <span class="dl">'</span><span class="s1">#FF0000</span><span class="dl">'</span><span class="p">,</span> <span class="na">lineWidth</span><span class="p">:</span> <span class="mi">2</span><span class="p">});</span>
    <span class="p">}</span>
  <span class="p">}</span>
  <span class="nx">canvasCtx</span><span class="p">.</span><span class="nx">restore</span><span class="p">();</span>
<span class="p">}</span>

<span class="kd">const</span> <span class="nx">hands</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">Hands</span><span class="p">({</span><span class="na">locateFile</span><span class="p">:</span> <span class="p">(</span><span class="nx">file</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="p">{</span>
  <span class="k">return</span> <span class="s2">`https://cdn.jsdelivr.net/npm/@mediapipe/hands/</span><span class="p">${</span><span class="nx">file</span><span class="p">}</span><span class="s2">`</span><span class="p">;</span>
<span class="p">}});</span>
<span class="nx">hands</span><span class="p">.</span><span class="nx">setOptions</span><span class="p">({</span>
  <span class="na">maxNumHands</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
  <span class="na">modelComplexity</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
  <span class="na">minDetectionConfidence</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span>
  <span class="na">minTrackingConfidence</span><span class="p">:</span> <span class="mf">0.5</span>
<span class="p">});</span>
<span class="nx">hands</span><span class="p">.</span><span class="nx">onResults</span><span class="p">(</span><span class="nx">onResults</span><span class="p">);</span>

<span class="kd">const</span> <span class="nx">camera</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">Camera</span><span class="p">(</span><span class="nx">videoElement</span><span class="p">,</span> <span class="p">{</span>
  <span class="na">onFrame</span><span class="p">:</span> <span class="k">async</span> <span class="p">()</span> <span class="o">=&gt;</span> <span class="p">{</span>
    <span class="k">await</span> <span class="nx">hands</span><span class="p">.</span><span class="nx">send</span><span class="p">({</span><span class="na">image</span><span class="p">:</span> <span class="nx">videoElement</span><span class="p">});</span>
  <span class="p">},</span>
  <span class="na">width</span><span class="p">:</span> <span class="mi">1280</span><span class="p">,</span>
  <span class="na">height</span><span class="p">:</span> <span class="mi">720</span>
<span class="p">});</span>
<span class="nx">camera</span><span class="p">.</span><span class="nx">start</span><span class="p">();</span>
<span class="o">&lt;</span><span class="sr">/script</span><span class="err">&gt;
</span></code></pre></div></div> <h3 id="android-solution-api"> <a href="https://google.github.io/mediapipe/solutions/hands.html#android-solution-api" class="anchor-heading" aria-labelledby="android-solution-api"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Android Solution API </h3> <p>Please first follow general <a href="https://google.github.io/mediapipe/getting_started/android_solutions.html">instructions</a> to add MediaPipe Gradle dependencies and try the Android Solution API in the companion <a href="https://github.com/google/mediapipe/tree/master/mediapipe/examples/android/solutions/hands">example Android Studio project</a>, and learn more in the usage example below.</p> <p>Supported configuration options:</p> <ul> <li><a href="https://google.github.io/mediapipe/solutions/hands.html#static_image_mode">staticImageMode</a></li> <li><a href="https://google.github.io/mediapipe/solutions/hands.html#max_num_hands">maxNumHands</a></li> <li>runOnGpu: Run the pipeline and the model inference on GPU or CPU.</li> </ul> <h4 id="camera-input"> <a href="https://google.github.io/mediapipe/solutions/hands.html#camera-input" class="anchor-heading" aria-labelledby="camera-input"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Camera Input </h4> <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// For camera input and result rendering with OpenGL.</span>
<span class="nc">HandsOptions</span> <span class="n">handsOptions</span> <span class="o">=</span>
    <span class="nc">HandsOptions</span><span class="o">.</span><span class="na">builder</span><span class="o">()</span>
        <span class="o">.</span><span class="na">setStaticImageMode</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
        <span class="o">.</span><span class="na">setMaxNumHands</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>
        <span class="o">.</span><span class="na">setRunOnGpu</span><span class="o">(</span><span class="kc">true</span><span class="o">).</span><span class="na">build</span><span class="o">();</span>
<span class="nc">Hands</span> <span class="n">hands</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">Hands</span><span class="o">(</span><span class="k">this</span><span class="o">,</span> <span class="n">handsOptions</span><span class="o">);</span>
<span class="n">hands</span><span class="o">.</span><span class="na">setErrorListener</span><span class="o">(</span>
    <span class="o">(</span><span class="n">message</span><span class="o">,</span> <span class="n">e</span><span class="o">)</span> <span class="o">-&gt;</span> <span class="nc">Log</span><span class="o">.</span><span class="na">e</span><span class="o">(</span><span class="no">TAG</span><span class="o">,</span> <span class="s">"MediaPipe Hands error:"</span> <span class="o">+</span> <span class="n">message</span><span class="o">));</span>

<span class="c1">// Initializes a new CameraInput instance and connects it to MediaPipe Hands Solution.</span>
<span class="nc">CameraInput</span> <span class="n">cameraInput</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">CameraInput</span><span class="o">(</span><span class="k">this</span><span class="o">);</span>
<span class="n">cameraInput</span><span class="o">.</span><span class="na">setNewFrameListener</span><span class="o">(</span>
    <span class="n">textureFrame</span> <span class="o">-&gt;</span> <span class="n">hands</span><span class="o">.</span><span class="na">send</span><span class="o">(</span><span class="n">textureFrame</span><span class="o">));</span>

<span class="c1">// Initializes a new GlSurfaceView with a ResultGlRenderer&lt;HandsResult&gt; instance</span>
<span class="c1">// that provides the interfaces to run user-defined OpenGL rendering code.</span>
<span class="c1">// See mediapipe/examples/android/solutions/hands/src/main/java/com/google/mediapipe/examples/hands/HandsResultGlRenderer.java</span>
<span class="c1">// as an example.</span>
<span class="nc">SolutionGlSurfaceView</span><span class="o">&lt;</span><span class="nc">HandsResult</span><span class="o">&gt;</span> <span class="n">glSurfaceView</span> <span class="o">=</span>
    <span class="k">new</span> <span class="nc">SolutionGlSurfaceView</span><span class="o">&lt;&gt;(</span>
        <span class="k">this</span><span class="o">,</span> <span class="n">hands</span><span class="o">.</span><span class="na">getGlContext</span><span class="o">(),</span> <span class="n">hands</span><span class="o">.</span><span class="na">getGlMajorVersion</span><span class="o">());</span>
<span class="n">glSurfaceView</span><span class="o">.</span><span class="na">setSolutionResultRenderer</span><span class="o">(</span><span class="k">new</span> <span class="nc">HandsResultGlRenderer</span><span class="o">());</span>
<span class="n">glSurfaceView</span><span class="o">.</span><span class="na">setRenderInputImage</span><span class="o">(</span><span class="kc">true</span><span class="o">);</span>

<span class="n">hands</span><span class="o">.</span><span class="na">setResultListener</span><span class="o">(</span>
    <span class="n">handsResult</span> <span class="o">-&gt;</span> <span class="o">{</span>
      <span class="k">if</span> <span class="o">(</span><span class="n">result</span><span class="o">.</span><span class="na">multiHandLandmarks</span><span class="o">().</span><span class="na">isEmpty</span><span class="o">())</span> <span class="o">{</span>
        <span class="k">return</span><span class="o">;</span>
      <span class="o">}</span>
      <span class="nc">NormalizedLandmark</span> <span class="n">wristLandmark</span> <span class="o">=</span>
          <span class="n">handsResult</span><span class="o">.</span><span class="na">multiHandLandmarks</span><span class="o">().</span><span class="na">get</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="na">getLandmarkList</span><span class="o">().</span><span class="na">get</span><span class="o">(</span><span class="nc">HandLandmark</span><span class="o">.</span><span class="na">WRIST</span><span class="o">);</span>
      <span class="nc">Log</span><span class="o">.</span><span class="na">i</span><span class="o">(</span>
          <span class="no">TAG</span><span class="o">,</span>
          <span class="nc">String</span><span class="o">.</span><span class="na">format</span><span class="o">(</span>
              <span class="s">"MediaPipe Hand wrist normalized coordinates (value range: [0, 1]): x=%f, y=%f"</span><span class="o">,</span>
              <span class="n">wristLandmark</span><span class="o">.</span><span class="na">getX</span><span class="o">(),</span> <span class="n">wristLandmark</span><span class="o">.</span><span class="na">getY</span><span class="o">()));</span>
      <span class="c1">// Request GL rendering.</span>
      <span class="n">glSurfaceView</span><span class="o">.</span><span class="na">setRenderData</span><span class="o">(</span><span class="n">handsResult</span><span class="o">);</span>
      <span class="n">glSurfaceView</span><span class="o">.</span><span class="na">requestRender</span><span class="o">();</span>
    <span class="o">});</span>

<span class="c1">// The runnable to start camera after the GLSurfaceView is attached.</span>
<span class="n">glSurfaceView</span><span class="o">.</span><span class="na">post</span><span class="o">(</span>
    <span class="o">()</span> <span class="o">-&gt;</span>
        <span class="n">cameraInput</span><span class="o">.</span><span class="na">start</span><span class="o">(</span>
            <span class="k">this</span><span class="o">,</span>
            <span class="n">hands</span><span class="o">.</span><span class="na">getGlContext</span><span class="o">(),</span>
            <span class="nc">CameraInput</span><span class="o">.</span><span class="na">CameraFacing</span><span class="o">.</span><span class="na">FRONT</span><span class="o">,</span>
            <span class="n">glSurfaceView</span><span class="o">.</span><span class="na">getWidth</span><span class="o">(),</span>
            <span class="n">glSurfaceView</span><span class="o">.</span><span class="na">getHeight</span><span class="o">()));</span>
</code></pre></div></div> <h4 id="image-input"> <a href="https://google.github.io/mediapipe/solutions/hands.html#image-input" class="anchor-heading" aria-labelledby="image-input"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Image Input </h4> <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// For reading images from gallery and drawing the output in an ImageView.</span>
<span class="nc">HandsOptions</span> <span class="n">handsOptions</span> <span class="o">=</span>
    <span class="nc">HandsOptions</span><span class="o">.</span><span class="na">builder</span><span class="o">()</span>
        <span class="o">.</span><span class="na">setStaticImageMode</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
        <span class="o">.</span><span class="na">setMaxNumHands</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>
        <span class="o">.</span><span class="na">setRunOnGpu</span><span class="o">(</span><span class="kc">true</span><span class="o">).</span><span class="na">build</span><span class="o">();</span>
<span class="nc">Hands</span> <span class="n">hands</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">Hands</span><span class="o">(</span><span class="k">this</span><span class="o">,</span> <span class="n">handsOptions</span><span class="o">);</span>

<span class="c1">// Connects MediaPipe Hands Solution to the user-defined ImageView instance that</span>
<span class="c1">// allows users to have the custom drawing of the output landmarks on it.</span>
<span class="c1">// See mediapipe/examples/android/solutions/hands/src/main/java/com/google/mediapipe/examples/hands/HandsResultImageView.java</span>
<span class="c1">// as an example.</span>
<span class="nc">HandsResultImageView</span> <span class="n">imageView</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">HandsResultImageView</span><span class="o">(</span><span class="k">this</span><span class="o">);</span>
<span class="n">hands</span><span class="o">.</span><span class="na">setResultListener</span><span class="o">(</span>
    <span class="n">handsResult</span> <span class="o">-&gt;</span> <span class="o">{</span>
      <span class="k">if</span> <span class="o">(</span><span class="n">result</span><span class="o">.</span><span class="na">multiHandLandmarks</span><span class="o">().</span><span class="na">isEmpty</span><span class="o">())</span> <span class="o">{</span>
        <span class="k">return</span><span class="o">;</span>
      <span class="o">}</span>
      <span class="kt">int</span> <span class="n">width</span> <span class="o">=</span> <span class="n">handsResult</span><span class="o">.</span><span class="na">inputBitmap</span><span class="o">().</span><span class="na">getWidth</span><span class="o">();</span>
      <span class="kt">int</span> <span class="n">height</span> <span class="o">=</span> <span class="n">handsResult</span><span class="o">.</span><span class="na">inputBitmap</span><span class="o">().</span><span class="na">getHeight</span><span class="o">();</span>
      <span class="nc">NormalizedLandmark</span> <span class="n">wristLandmark</span> <span class="o">=</span>
          <span class="n">handsResult</span><span class="o">.</span><span class="na">multiHandLandmarks</span><span class="o">().</span><span class="na">get</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="na">getLandmarkList</span><span class="o">().</span><span class="na">get</span><span class="o">(</span><span class="nc">HandLandmark</span><span class="o">.</span><span class="na">WRIST</span><span class="o">);</span>
      <span class="nc">Log</span><span class="o">.</span><span class="na">i</span><span class="o">(</span>
          <span class="no">TAG</span><span class="o">,</span>
          <span class="nc">String</span><span class="o">.</span><span class="na">format</span><span class="o">(</span>
              <span class="s">"MediaPipe Hand wrist coordinates (pixel values): x=%f, y=%f"</span><span class="o">,</span>
              <span class="n">wristLandmark</span><span class="o">.</span><span class="na">getX</span><span class="o">()</span> <span class="o">*</span> <span class="n">width</span><span class="o">,</span> <span class="n">wristLandmark</span><span class="o">.</span><span class="na">getY</span><span class="o">()</span> <span class="o">*</span> <span class="n">height</span><span class="o">));</span>
      <span class="c1">// Request canvas drawing.</span>
      <span class="n">imageView</span><span class="o">.</span><span class="na">setHandsResult</span><span class="o">(</span><span class="n">handsResult</span><span class="o">);</span>
      <span class="n">runOnUiThread</span><span class="o">(()</span> <span class="o">-&gt;</span> <span class="n">imageView</span><span class="o">.</span><span class="na">update</span><span class="o">());</span>
    <span class="o">});</span>
<span class="n">hands</span><span class="o">.</span><span class="na">setErrorListener</span><span class="o">(</span>
    <span class="o">(</span><span class="n">message</span><span class="o">,</span> <span class="n">e</span><span class="o">)</span> <span class="o">-&gt;</span> <span class="nc">Log</span><span class="o">.</span><span class="na">e</span><span class="o">(</span><span class="no">TAG</span><span class="o">,</span> <span class="s">"MediaPipe Hands error:"</span> <span class="o">+</span> <span class="n">message</span><span class="o">));</span>

<span class="c1">// ActivityResultLauncher to get an image from the gallery as Bitmap.</span>
<span class="nc">ActivityResultLauncher</span><span class="o">&lt;</span><span class="nc">Intent</span><span class="o">&gt;</span> <span class="n">imageGetter</span> <span class="o">=</span>
    <span class="n">registerForActivityResult</span><span class="o">(</span>
        <span class="k">new</span> <span class="nc">ActivityResultContracts</span><span class="o">.</span><span class="na">StartActivityForResult</span><span class="o">(),</span>
        <span class="n">result</span> <span class="o">-&gt;</span> <span class="o">{</span>
          <span class="nc">Intent</span> <span class="n">resultIntent</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="na">getData</span><span class="o">();</span>
          <span class="k">if</span> <span class="o">(</span><span class="n">resultIntent</span> <span class="o">!=</span> <span class="kc">null</span> <span class="o">&amp;&amp;</span> <span class="n">result</span><span class="o">.</span><span class="na">getResultCode</span><span class="o">()</span> <span class="o">==</span> <span class="no">RESULT_OK</span><span class="o">)</span> <span class="o">{</span>
            <span class="nc">Bitmap</span> <span class="n">bitmap</span> <span class="o">=</span> <span class="kc">null</span><span class="o">;</span>
            <span class="k">try</span> <span class="o">{</span>
              <span class="n">bitmap</span> <span class="o">=</span>
                  <span class="nc">MediaStore</span><span class="o">.</span><span class="na">Images</span><span class="o">.</span><span class="na">Media</span><span class="o">.</span><span class="na">getBitmap</span><span class="o">(</span>
                      <span class="k">this</span><span class="o">.</span><span class="na">getContentResolver</span><span class="o">(),</span> <span class="n">resultIntent</span><span class="o">.</span><span class="na">getData</span><span class="o">());</span>
              <span class="c1">// Please also rotate the Bitmap based on its orientation.</span>
            <span class="o">}</span> <span class="k">catch</span> <span class="o">(</span><span class="nc">IOException</span> <span class="n">e</span><span class="o">)</span> <span class="o">{</span>
              <span class="nc">Log</span><span class="o">.</span><span class="na">e</span><span class="o">(</span><span class="no">TAG</span><span class="o">,</span> <span class="s">"Bitmap reading error:"</span> <span class="o">+</span> <span class="n">e</span><span class="o">);</span>
            <span class="o">}</span>
            <span class="k">if</span> <span class="o">(</span><span class="n">bitmap</span> <span class="o">!=</span> <span class="kc">null</span><span class="o">)</span> <span class="o">{</span>
              <span class="n">hands</span><span class="o">.</span><span class="na">send</span><span class="o">(</span><span class="n">bitmap</span><span class="o">);</span>
            <span class="o">}</span>
          <span class="o">}</span>
        <span class="o">});</span>
<span class="nc">Intent</span> <span class="n">pickImageIntent</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">Intent</span><span class="o">(</span><span class="nc">Intent</span><span class="o">.</span><span class="na">ACTION_PICK</span><span class="o">);</span>
<span class="n">pickImageIntent</span><span class="o">.</span><span class="na">setDataAndType</span><span class="o">(</span><span class="nc">MediaStore</span><span class="o">.</span><span class="na">Images</span><span class="o">.</span><span class="na">Media</span><span class="o">.</span><span class="na">INTERNAL_CONTENT_URI</span><span class="o">,</span> <span class="s">"image/*"</span><span class="o">);</span>
<span class="n">imageGetter</span><span class="o">.</span><span class="na">launch</span><span class="o">(</span><span class="n">pickImageIntent</span><span class="o">);</span>
</code></pre></div></div> <h4 id="video-input"> <a href="https://google.github.io/mediapipe/solutions/hands.html#video-input" class="anchor-heading" aria-labelledby="video-input"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Video Input </h4> <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// For video input and result rendering with OpenGL.</span>
<span class="nc">HandsOptions</span> <span class="n">handsOptions</span> <span class="o">=</span>
    <span class="nc">HandsOptions</span><span class="o">.</span><span class="na">builder</span><span class="o">()</span>
        <span class="o">.</span><span class="na">setStaticImageMode</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
        <span class="o">.</span><span class="na">setMaxNumHands</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>
        <span class="o">.</span><span class="na">setRunOnGpu</span><span class="o">(</span><span class="kc">true</span><span class="o">).</span><span class="na">build</span><span class="o">();</span>
<span class="nc">Hands</span> <span class="n">hands</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">Hands</span><span class="o">(</span><span class="k">this</span><span class="o">,</span> <span class="n">handsOptions</span><span class="o">);</span>
<span class="n">hands</span><span class="o">.</span><span class="na">setErrorListener</span><span class="o">(</span>
    <span class="o">(</span><span class="n">message</span><span class="o">,</span> <span class="n">e</span><span class="o">)</span> <span class="o">-&gt;</span> <span class="nc">Log</span><span class="o">.</span><span class="na">e</span><span class="o">(</span><span class="no">TAG</span><span class="o">,</span> <span class="s">"MediaPipe Hands error:"</span> <span class="o">+</span> <span class="n">message</span><span class="o">));</span>

<span class="c1">// Initializes a new VideoInput instance and connects it to MediaPipe Hands Solution.</span>
<span class="nc">VideoInput</span> <span class="n">videoInput</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">VideoInput</span><span class="o">(</span><span class="k">this</span><span class="o">);</span>
<span class="n">videoInput</span><span class="o">.</span><span class="na">setNewFrameListener</span><span class="o">(</span>
    <span class="n">textureFrame</span> <span class="o">-&gt;</span> <span class="n">hands</span><span class="o">.</span><span class="na">send</span><span class="o">(</span><span class="n">textureFrame</span><span class="o">));</span>

<span class="c1">// Initializes a new GlSurfaceView with a ResultGlRenderer&lt;HandsResult&gt; instance</span>
<span class="c1">// that provides the interfaces to run user-defined OpenGL rendering code.</span>
<span class="c1">// See mediapipe/examples/android/solutions/hands/src/main/java/com/google/mediapipe/examples/hands/HandsResultGlRenderer.java</span>
<span class="c1">// as an example.</span>
<span class="nc">SolutionGlSurfaceView</span><span class="o">&lt;</span><span class="nc">HandsResult</span><span class="o">&gt;</span> <span class="n">glSurfaceView</span> <span class="o">=</span>
    <span class="k">new</span> <span class="nc">SolutionGlSurfaceView</span><span class="o">&lt;&gt;(</span>
        <span class="k">this</span><span class="o">,</span> <span class="n">hands</span><span class="o">.</span><span class="na">getGlContext</span><span class="o">(),</span> <span class="n">hands</span><span class="o">.</span><span class="na">getGlMajorVersion</span><span class="o">());</span>
<span class="n">glSurfaceView</span><span class="o">.</span><span class="na">setSolutionResultRenderer</span><span class="o">(</span><span class="k">new</span> <span class="nc">HandsResultGlRenderer</span><span class="o">());</span>
<span class="n">glSurfaceView</span><span class="o">.</span><span class="na">setRenderInputImage</span><span class="o">(</span><span class="kc">true</span><span class="o">);</span>

<span class="n">hands</span><span class="o">.</span><span class="na">setResultListener</span><span class="o">(</span>
    <span class="n">handsResult</span> <span class="o">-&gt;</span> <span class="o">{</span>
      <span class="k">if</span> <span class="o">(</span><span class="n">result</span><span class="o">.</span><span class="na">multiHandLandmarks</span><span class="o">().</span><span class="na">isEmpty</span><span class="o">())</span> <span class="o">{</span>
        <span class="k">return</span><span class="o">;</span>
      <span class="o">}</span>
      <span class="nc">NormalizedLandmark</span> <span class="n">wristLandmark</span> <span class="o">=</span>
          <span class="n">handsResult</span><span class="o">.</span><span class="na">multiHandLandmarks</span><span class="o">().</span><span class="na">get</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="na">getLandmarkList</span><span class="o">().</span><span class="na">get</span><span class="o">(</span><span class="nc">HandLandmark</span><span class="o">.</span><span class="na">WRIST</span><span class="o">);</span>
      <span class="nc">Log</span><span class="o">.</span><span class="na">i</span><span class="o">(</span>
          <span class="no">TAG</span><span class="o">,</span>
          <span class="nc">String</span><span class="o">.</span><span class="na">format</span><span class="o">(</span>
              <span class="s">"MediaPipe Hand wrist normalized coordinates (value range: [0, 1]): x=%f, y=%f"</span><span class="o">,</span>
              <span class="n">wristLandmark</span><span class="o">.</span><span class="na">getX</span><span class="o">(),</span> <span class="n">wristLandmark</span><span class="o">.</span><span class="na">getY</span><span class="o">()));</span>
      <span class="c1">// Request GL rendering.</span>
      <span class="n">glSurfaceView</span><span class="o">.</span><span class="na">setRenderData</span><span class="o">(</span><span class="n">handsResult</span><span class="o">);</span>
      <span class="n">glSurfaceView</span><span class="o">.</span><span class="na">requestRender</span><span class="o">();</span>
    <span class="o">});</span>

<span class="nc">ActivityResultLauncher</span><span class="o">&lt;</span><span class="nc">Intent</span><span class="o">&gt;</span> <span class="n">videoGetter</span> <span class="o">=</span>
    <span class="n">registerForActivityResult</span><span class="o">(</span>
        <span class="k">new</span> <span class="nc">ActivityResultContracts</span><span class="o">.</span><span class="na">StartActivityForResult</span><span class="o">(),</span>
        <span class="n">result</span> <span class="o">-&gt;</span> <span class="o">{</span>
          <span class="nc">Intent</span> <span class="n">resultIntent</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="na">getData</span><span class="o">();</span>
          <span class="k">if</span> <span class="o">(</span><span class="n">resultIntent</span> <span class="o">!=</span> <span class="kc">null</span><span class="o">)</span> <span class="o">{</span>
            <span class="k">if</span> <span class="o">(</span><span class="n">result</span><span class="o">.</span><span class="na">getResultCode</span><span class="o">()</span> <span class="o">==</span> <span class="no">RESULT_OK</span><span class="o">)</span> <span class="o">{</span>
              <span class="n">glSurfaceView</span><span class="o">.</span><span class="na">post</span><span class="o">(</span>
                  <span class="o">()</span> <span class="o">-&gt;</span>
                      <span class="n">videoInput</span><span class="o">.</span><span class="na">start</span><span class="o">(</span>
                          <span class="k">this</span><span class="o">,</span>
                          <span class="n">resultIntent</span><span class="o">.</span><span class="na">getData</span><span class="o">(),</span>
                          <span class="n">hands</span><span class="o">.</span><span class="na">getGlContext</span><span class="o">(),</span>
                          <span class="n">glSurfaceView</span><span class="o">.</span><span class="na">getWidth</span><span class="o">(),</span>
                          <span class="n">glSurfaceView</span><span class="o">.</span><span class="na">getHeight</span><span class="o">()));</span>
            <span class="o">}</span>
          <span class="o">}</span>
        <span class="o">});</span>
<span class="nc">Intent</span> <span class="n">pickVideoIntent</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">Intent</span><span class="o">(</span><span class="nc">Intent</span><span class="o">.</span><span class="na">ACTION_PICK</span><span class="o">);</span>
<span class="n">pickVideoIntent</span><span class="o">.</span><span class="na">setDataAndType</span><span class="o">(</span><span class="nc">MediaStore</span><span class="o">.</span><span class="na">Video</span><span class="o">.</span><span class="na">Media</span><span class="o">.</span><span class="na">INTERNAL_CONTENT_URI</span><span class="o">,</span> <span class="s">"video/*"</span><span class="o">);</span>
<span class="n">videoGetter</span><span class="o">.</span><span class="na">launch</span><span class="o">(</span><span class="n">pickVideoIntent</span><span class="o">);</span>
</code></pre></div></div> <h2 id="example-apps"> <a href="https://google.github.io/mediapipe/solutions/hands.html#example-apps" class="anchor-heading" aria-labelledby="example-apps"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Example Apps </h2> <p>Please first see general instructions for <a href="https://google.github.io/mediapipe/getting_started/android.html">Android</a>, <a href="https://google.github.io/mediapipe/getting_started/ios.html">iOS</a> and <a href="https://google.github.io/mediapipe/getting_started/cpp.html">desktop</a> on how to build MediaPipe examples.</p> <p>Note: To visualize a graph, copy the graph and paste it into <a href="https://viz.mediapipe.dev/">MediaPipe Visualizer</a>. For more information on how to visualize its associated subgraphs, please see <a href="https://google.github.io/mediapipe/tools/visualizer.html">visualizer documentation</a>.</p> <h3 id="mobile"> <a href="https://google.github.io/mediapipe/solutions/hands.html#mobile" class="anchor-heading" aria-labelledby="mobile"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Mobile </h3> <h4 id="main-example"> <a href="https://google.github.io/mediapipe/solutions/hands.html#main-example" class="anchor-heading" aria-labelledby="main-example"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Main Example </h4> <ul> <li>Graph: <a href="https://github.com/google/mediapipe/tree/master/mediapipe/graphs/hand_tracking/hand_tracking_mobile.pbtxt"><code class="language-plaintext highlighter-rouge">mediapipe/graphs/hand_tracking/hand_tracking_mobile.pbtxt</code></a></li> <li>Android target: <a href="https://drive.google.com/open?id=1uCjS0y0O0dTDItsMh8x2cf4-l3uHW1vE">(or download prebuilt ARM64 APK)</a> <a href="https://github.com/google/mediapipe/tree/master/mediapipe/examples/android/src/java/com/google/mediapipe/apps/handtrackinggpu/BUILD"><code class="language-plaintext highlighter-rouge">mediapipe/examples/android/src/java/com/google/mediapipe/apps/handtrackinggpu:handtrackinggpu</code></a></li> <li>iOS target: <a href="https://github.com/google/mediapipe/tree/master/mediapipe/examples/ios/handtrackinggpu/BUILD"><code class="language-plaintext highlighter-rouge">mediapipe/examples/ios/handtrackinggpu:HandTrackingGpuApp</code></a></li> </ul> <p>Tip: Maximum number of hands to detect/process is set to 2 by default. To change it, for Android modify <code class="language-plaintext highlighter-rouge">NUM_HANDS</code> in <a href="https://github.com/google/mediapipe/tree/master/mediapipe/examples/android/src/java/com/google/mediapipe/apps/handtrackinggpu/MainActivity.java">MainActivity.java</a>, and for iOS modify <code class="language-plaintext highlighter-rouge">kNumHands</code> in <a href="https://github.com/google/mediapipe/tree/master/mediapipe/examples/ios/handtrackinggpu/HandTrackingViewController.mm">HandTrackingViewController.mm</a>.</p> <h4 id="palmhand-detection-only-no-landmarks"> <a href="https://google.github.io/mediapipe/solutions/hands.html#palmhand-detection-only-no-landmarks" class="anchor-heading" aria-labelledby="palmhand-detection-only-no-landmarks"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Palm/Hand Detection Only (no landmarks) </h4> <ul> <li>Graph: <a href="https://github.com/google/mediapipe/tree/master/mediapipe/graphs/hand_tracking/hand_detection_mobile.pbtxt"><code class="language-plaintext highlighter-rouge">mediapipe/graphs/hand_tracking/hand_detection_mobile.pbtxt</code></a></li> <li>Android target: <a href="https://drive.google.com/open?id=1qUlTtH7Ydg-wl_H6VVL8vueu2UCTu37E">(or download prebuilt ARM64 APK)</a> <a href="https://github.com/google/mediapipe/tree/master/mediapipe/examples/android/src/java/com/google/mediapipe/apps/handdetectiongpu/BUILD"><code class="language-plaintext highlighter-rouge">mediapipe/examples/android/src/java/com/google/mediapipe/apps/handdetectiongpu:handdetectiongpu</code></a></li> <li>iOS target: <a href="https://github.com/google/mediapipe/tree/master/mediapipe/examples/ios/handdetectiongpu/BUILD"><code class="language-plaintext highlighter-rouge">mediapipe/examples/ios/handdetectiongpu:HandDetectionGpuApp</code></a></li> </ul> <h3 id="desktop"> <a href="https://google.github.io/mediapipe/solutions/hands.html#desktop" class="anchor-heading" aria-labelledby="desktop"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Desktop </h3> <ul> <li>Running on CPU <ul> <li>Graph: <a href="https://github.com/google/mediapipe/tree/master/mediapipe/graphs/hand_tracking/hand_tracking_desktop_live.pbtxt"><code class="language-plaintext highlighter-rouge">mediapipe/graphs/hand_tracking/hand_tracking_desktop_live.pbtxt</code></a></li> <li>Target: <a href="https://github.com/google/mediapipe/tree/master/mediapipe/examples/desktop/hand_tracking/BUILD"><code class="language-plaintext highlighter-rouge">mediapipe/examples/desktop/hand_tracking:hand_tracking_cpu</code></a></li> </ul> </li> <li>Running on GPU <ul> <li>Graph: <a href="https://github.com/google/mediapipe/tree/master/mediapipe/graphs/hand_tracking/hand_tracking_desktop_gpu.pbtxt"><code class="language-plaintext highlighter-rouge">mediapipe/graphs/hand_tracking/hand_tracking_desktop_live_gpu.pbtxt</code></a></li> <li>Target: <a href="https://github.com/google/mediapipe/tree/master/mediapipe/examples/desktop/hand_tracking/BUILD"><code class="language-plaintext highlighter-rouge">mediapipe/examples/desktop/hand_tracking:hand_tracking_gpu</code></a></li> </ul> </li> </ul> <p>Tip: Maximum number of hands to detect/process is set to 2 by default. To change it, in the graph file modify the option of <code class="language-plaintext highlighter-rouge">ConstantSidePacketCalculator</code>.</p> <h2 id="resources"> <a href="https://google.github.io/mediapipe/solutions/hands.html#resources" class="anchor-heading" aria-labelledby="resources"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Resources </h2> <ul> <li>Google AI Blog: <a href="https://ai.googleblog.com/2019/08/on-device-real-time-hand-tracking-with.html">On-Device, Real-Time Hand Tracking with MediaPipe</a></li> <li>TensorFlow Blog: <a href="https://blog.tensorflow.org/2020/03/face-and-hand-tracking-in-browser-with-mediapipe-and-tensorflowjs.html">Face and hand tracking in the browser with MediaPipe and TensorFlow.js</a></li> <li>Paper: <a href="https://arxiv.org/abs/2006.10214">MediaPipe Hands: On-device Real-time Hand Tracking</a> (<a href="https://www.youtube.com/watch?v=I-UOrvxxXEk">presentation</a>)</li> <li><a href="https://google.github.io/mediapipe/solutions/models.html#hands">Models and model cards</a></li> <li><a href="https://code.mediapipe.dev/codepen/hands">Web demo</a></li> <li><a href="https://code.mediapipe.dev/codepen/defrost">Fun application</a></li> <li><a href="https://mediapipe.page.link/hands_py_colab">Python Colab</a></li> </ul> <hr> <footer> <p class="text-small text-grey-dk-100 mb-0">© 2020 GOOGLE LLC | <a href="https://policies.google.com/privacy">PRIVACY POLICY</a> | <a href="https://policies.google.com/terms">TERMS OF SERVICE</a></p> </footer> </div> </div> <div class="search-overlay"></div> </div>  
</body></html>